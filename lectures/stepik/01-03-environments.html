<h2 style="text-align:center">Environments, Runtime Support and Cross-Compilation</h2>

<p>Programs are rarely work in isolation; as a rule they rely on a certain environment: operating system, system- and
  user-level libraries, etc. An important component of this environment is a <em>runtime support library</em>. This
  library contains an implementation of certain programming language constructs which are more beneficent to implement
  as a library than to built in a compiler itself, for example, memory managements and synchronization primitives, etc.
  The invocation of these primitives is generated by a compiler; as a rule, they can not be accessed from programs on
  the user level. In contrast, <em>standard library</em> contains an initial implementation of useful data structures
  and functions in terms of the source programming language, for example, input-output functions, standard data types,
  collection implementations, etc.</p>

<p>Since compiler is a program itself, it also requires a certain environment, called <em>compilation environment</em>.
  On the other hand, the environment for which compiler generates its output is called <em>target environment</em>.
  Usually these two coincide &mdash; for example, out &lambda;ama compiler works under Linux on x86 processor, and
  generates programs which work under Linux on x86.</p>

<p>However, in general case, compilation environment can be different from the target one. In this case the compiler is
  called <em>cross-compiler</em>. For example, we could rewrite our &lambda;aMa compiler into a cross-one, which, still
  running on x86, would generate code for ARM.</p>

<p>A typical scenario for cross-compilation is <em>bootstrapping</em> (see below) or the development of embedded systems
  when the target platform is not enough performant/well-equipped to support the execution of a compiler.</p>

<h2 style="text-align:center">Bootstrapping</h2>

<p>An interesting (and practically important) operation involving compilers is their <em>bootstrapping</em>. This term
  denotes the implementation of a compiler in its own source languages (i.e. when implementation language coincides with
  the source one). The term itself originates from an idiom describing a process of pulling oneself up by the hooks on
  the back of their own boots.</p>

<p style="text-align:center"><img alt="" height="468" name="bootstrapping.png"
                                  src="https://ucarecdn.com/869927e2-20bc-49fe-9dea-b95c8d6f2bba/" width="737"/></p>

<p>The bootstrapping of a compiler for a new language (for which no compiler yet exists) is comprised of its
  implementation in some other language and then rewriting it in this new language using just written compiler. For
  example, in such a way the &lambda;aMa compiler was acquired (<strong>not really yet</strong>): initially it was
  implemented in <strong>OCaml</strong> and then reimplemented in &lambda;aMa itself.</p>

<p>If some compiler for the language of interest already exists, but works on some other platform, then it is possible
  for implement a <em>cross-compiler</em> which works on that platform but generates code for the platform of interest.
  Then this compiler can be compiled by itself &mdash; this is the conventional way, for example, to port
  <strong>GCC</strong> compilers to other platforms.</p>

<p>Finally, if nothing useful exists beside the assembler for the platform of interest, then this assembler itself can
  be used to implement a small subset of the desirable language; then this subset can be used to implement a wider
  subset, and so on. This is how modern compiler/language zoo was built historically.</p>

<p>Compiler bootstrapping is an ideologically important step: first, it assesses the expressiveness of the language;
  second, ir witnesses the maturity of the compiler, since for a new language its compiler, as a rule, is the first
  large and complex program.</p>

<h2 style="text-align:center">Complete vs. Partial Correctness</h2>

<p>Compiler (as any other translator) has to syntactically transform a program in one language into a program in
  another, preserving its semantics. In practice, however there are some subtleties. Let us have a program
  <strong>p</strong>. We denote by</p>

<p><span class="math-tex">\(x \xrightarrow{\displaystyle{\textbf{p}}} y\)</span></p>

<p>the fact that <strong>p</strong> on input <em>x</em> terminates with the output <em>y</em> (as we know, there may be
  two other outcomes: <strong>p</strong> crashes on input <em>x</em> or <strong>p</strong> loops forever on input
  <em>x</em>).</p>

<p>Let us have a compiler, let <em>source</em> be some source program, and let <em>target</em> be a target program after
  the compilation. We will say that a compiler is <em>completely correct</em> if for arbitrary <em>source</em>-<em>target</em>
  pair and arbitrary input-output pairs <em>x</em> and <em>y</em></p>

<p><span class="math-tex">\(x\xrightarrow{\displaystyle{source}}y \Longleftrightarrow x\xrightarrow{\displaystyle{target}}y\)</span>
</p>

<p>In other words, the behaviour of the source and compiled programs is indistinguishable: on the same input both either
  terminate with the same results, or crash/loop.</p>

<p>Consider, however, the following simple program:</p>

<pre>
<code># include &lt;stdio.h&gt;

static int d = 0;

int main (int argc, char *argv[]) {
  int x;

  x = argc / d;

  return 255;
}</code></pre>

<p>A brief analysis reveals that this program has to crash on each input. Indeed, the variable &ldquo;<code>d</code>&rdquo;
  has initial value zero and cannot be reassigned elsewhere (due to <code>static</code> storage class), and division by
  zero gives a runtime error. We could, alternatively, try to compile this program with &ldquo;<tt>gcc -O0</tt>&rdquo;
  command and see that it, indeed, crashes.</p>

<p>On the other hand, a more careful analysis shows that the value of the variable &ldquo;<code>x</code>&rdquo;, during
  the computation of which the error occurs, actually is never used, so its computation can be completely omitted. And,
  indeed, if we compile this program with the command &ldquo;<tt>gcc -O3</tt>&rdquo;, it terminates successfully with
  return code 255! This is because the option &ldquo;<tt>-O3</tt>&rdquo; turns on the optimizations, and one of those
  &mdash; <em>dead code elimination</em> &mdash; does exactly what we envisioned.</p>

<p>Thus, we can see that in practice target programs not always completely equivalent to the source ones: they can
  deliver some results on inputs, for which the source ones loop or crash. This property is called <em>partial
    correctness</em>, and can be formally specified as follows: for arbitrary input-output values <em>x</em> and
  <em>y</em>, and for arbitrary source and target programs <em>source</em> and <em>target</em></p>

<p><span class="math-tex">\(x\xrightarrow{\displaystyle{source}}y \Longrightarrow x\xrightarrow{\displaystyle{target}}y\)</span>
</p>

<p>This means, that when the source program terminates with a definite result, the target also does so with the same
  result; however, the target one can still deliver some output values for inputs on which the source program is not
  defined. In other words, compilers are allowed to <em>extend the domains</em> of programs they compile. The majority
  of compilers (and other tools as well) are partially correct.</p>
