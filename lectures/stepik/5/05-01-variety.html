<!--<h1>Abstract Stack Machine</h1>-->

  <p>The notion of abstract machine is a convenient concept in the field of programming languages, compilers and tools.
  As the name suggests, abstract machine is a hypothetical computational device which fills the gap between a high-level language
  and an actual hardware. It, therefore, introduces an additional intermediate abstraction level which facilitates the
  decomposition of many compiler implementation and program analysis tasks. This decomposition makes it possible to separate
  certain implementation subtasks, solve them and assess the correctness of solutions independently.
  </p>

  <p>An important question is how an abstract machine can be specified and built. Do we need a blueprint, what appliances and equipment
  should we use for its manufacturing? Fortunately, it turns out that we already have all what we need in our toolbox. For us an
  abstract machine is just a language, and to specify an abstract machine we need to specify the syntax and semantics of
  this language. Implementing an abstract machine amounts to implementing its interpreter. In this section we
  give the syntax and semantics of a &lambda;aMa-specific abstract stack machine, describe the compiler from straight-line
  programs language into this abstract machine and prove its correctness. But, first, we briefly survey the variety of existing
  flavours of abstract machines and discuss the motivation for the basic features of that we chose.</p>

<h2>The Variety of Abstract Machines</h2>

  <p>Abstract machines share a lot of common features with actual hardware. They are programmable devices, and their
  programs consist of instructions each of which is capable of performing a rather simple operation. On the other hand,
  abstract machines often provide a direct way of representing and using <em>meta-information</em> specific to a certain
  lanaguage or a group of languages this abstract machine is devised to support. This may include types, object structures, etc.
  For example, JVM directly supports such construct as virtual method call, which for a real hardware has to be
    implemented using the knowledge of actual virtual methods table layout, etc.</p>

<p style="text-align: center"><span class="math-tex">\(x*y+3\)</span></p>
<p style="text-align: center" id="expr"><em>Expression</em></p>
<br>

<pre>
<code>  LD x
  LD y
  MUL
  CONST 3
  ADD</code></pre>
<p style="text-align: center" id="expr-stack"><em>Stack Machine Code</em></p>
<br>

<pre>
<code>  MUL x, y, %1
  ADD %1, 3, %2</code></pre>
<p style="text-align: center" id="expr-3addr"><em>Three-address Code</em></p>
<br>

<pre><code>  MOV y, %1
  MUL x, %1
  ADD 3, %1</code></pre>
<p style="text-align: center"><em>Two-address Code</em></p>
<br>
<p style="text-align: center" id="expr-2addr"><em>An Expression and Its Abstract Machine Code</em></p>

  There are different flavours of abstract machines. For now, as we are dealing with rather a simple language of
  straight-line programs, only one essential feature is important: the representation of <em>temporaries</em>.

  In our language (and the majority of conventional programming languages) expressions can contain an arbitrary
  number of operators. However, actual hardware (and the majority of abstract machines) cannot evaluate arbitrarily
  large expressions "in one step". It evaluates them operator by operator, storing somewhere intermediate results, otherwise
  called <em>temporary values</em>. There are two major disciplines to work with temporaries:

  <ul>
  <li>Using a <em>stack</em>. With this discipline all temporary values are stored on a stack specifically disignated
  for this purpose. Thus, all operators take the operands from the stack and put the result back. This, in particular,
    means that the majority of instructions do not have explicit operands.</li>

  <li>Using a potentially infinite number of named locations (often called <em>pseudo-registers</em>). Under this approach
  the operands of each instruction (if any) are explicitly annotated. There are two commonly used special cases: <em>three-address code</em>,
  when an instruction can have up to three distinct operands (two for arguments and one for the result) and
  <em>two-address code</em>, when an instruction can have no more than two operands, one of which serves simultaneously
    as an argument and as the result.</li>
  </ul>

  <p>All these versions of abstract machines have their merits and shortcomings, and rather easier to switch to and from. Stack code is known
  to be very compact (indeed, it does not require extra space to specify the operands for the majority of instructions); it is also a
  little bit easier to generate. As the same time code with explicit operands is easier to analyize and transform, and faster to
  interpret. It worth mentioning that the distinction stack vs. explicit operands by no means separates abstract machines from
  real hardware: there some examples of the latter which implement stack architecture (the most notable, probably, is now late
    Intel 8087 floating-point coprocessor).</p>

  <p>In our case we favoured stack machine over others since the compilation to stack code posesses some nice invariants and
  its correctness can be formally assessed easily. In addition the archiecture of <span style="font-variant-caps: all-small-caps">x86</span> is very close to two-address
  code, so dealing with stack abstract machine allows us to consider a broader class of architectures.</p>

<h2>Syntax and Semantics</h2>

  The syntax of abstract stack machine language is shown below:

<p style="text-align:center">
<span class="math-tex">\(
  \begin{array}{rcl}
  \mathscr{I} & = & \mathbf{BINOP\ \otimes}\\
  &   & \mathbf{CONST \ \mathbb{N}}\\
  &   & \mathbf{LD\ \mathscr{X}}\\
  &   & \mathbf{ST\ \mathscr{X}}\\
  &   & \mathbf{READ}\\
  &   & \mathbf{WRITE}\\[2mm]
  \mathscr{S} & = & \epsilon\\
  &   & \mathscr{I}\mathscr{S}
  \end{array}
\)</span></p>

  <p>We have here two syntactic categories — <em>instructions</em>
<span class="math-tex">\(\mathscr{I}\)</span> and <em>programs</em>
<span class="math-tex">\(\mathscr{P}\)</span>.</p>

  <p>There are six types of instructions, and only two types of programs — an empty program <span class="math-tex">\(\epsilon\)</span> and a composite
  program which consists of an instruction and a residual program. In essence the programs of stack machine
  are just lists of instructions. Some of the instructions have operands: for <span class="math-tex">\(\mathbf{BINOP}\)</span> an operand is a name of binary operator
  from the source language, for <span class="math-tex">\(\mathbf{CONST}\)</span> it is a natural number, for <span class="math-tex">\(\mathbf{LD}\)</span> and <span class="math-tex">\(\mathbf{ST}\)</span> — the names of
  variables. We can notice that the language of stack machine is very simple, much simpler than that for the straight-line programs. Yet it
  possesses enough expressive power to perform the same calculations as an arbitrary straigh-line program! We assess this property
  by implementing a compiler and proving its correctness.</p>

  <p>Before giving a formal semantics for stack machine we first give an informal description of how it functions. The stack
  machine operates in a similar environment as straight-line programs. It reads and writes numbers from/to a world, and it
  posesses an internal state which binds (some) variables names to integer values. Beside that, stack machine has a
  stack of integers at its discretion. In a nutshell, this stack contains temporary values which are nowhere to place
  otherwise. The stack machine program executes instruction by instruction starting from the first instruction.
  Each instruction modifies the configuration of the stack machine (state, stack, or world) and can either succeed or
  fail (crash). The machine stops when there are no instructions left to execute; in this case the contents of
  the output stream is taken as the result of stack program evaluation.</p>

<p style="text-align:center">
<span class="math-tex">\(
\def\padding{\phantom{X}}
\def\transarrow{\xrightarrow}
\newcommand{\setpadding}[1]{\def\padding{#1}}
\def\subarrow{}
\newcommand{\setsubarrow}[1]{\def\subarrow{#1}}
\newcommand{\trans}[3]{{#1}\transarrow{\padding{\textstyle #2}\padding}\subarrow{#3}}
\newcommand{\inbr}[1]{\left<{#1}\right>}
\newcommand{\trule}[2]{\frac{#1}{#2}}

  \setsubarrow{_{SM}}

  \def\arraystretch{3}
  \def\arraystretch{3}
  \begin{array}{cr}
  \trans{c}{\epsilon}{c}&            Stop_{SM}\\
  \trule{\trans{\inbr{\sigma,\,(x\oplus y)s,\,\omega}}{p}{c^\prime}}{\trans{\inbr{\sigma,\,yxs,\,\omega}}{[\mathbf{BINOP \ \otimes}]p}{c^\prime}}&\ \ \ \ \ \ \ \ \ \ \ \ Binop_{SM}\\
  \trule{\trans{\inbr{\sigma,\,zs,\,\omega}}{p}{c^\prime}}{\trans{\inbr{\sigma,\,s,\,\omega}}{[\mathbf{CONST \ z}]p}{c^\prime}}&\ \ \ \ \ \ \ \ \ \ \ \ Const_{SM}\\
  \trule{\inbr{z,\,\omega^\prime}=\mathbf{read}{\ \omega},\,\trans{\inbr{\sigma,\,zs,\,\omega^\prime}}{p}{c^\prime}}{\trans{\inbr{\sigma,\,s,\,\omega}}{[\mathbf{READ}]\,p}{c^\prime}}&\ \ \ \ \ \ \ \ \ \ \ \ Read_{SM}\\
  \trule{\trans{\inbr{\sigma,\,s,\,\mathbf{write}{\ z\ \omega}}}{p}{c^\prime}}{\trans{\inbr{\sigma,\,zs,\,\omega}}{[\mathbf{WRITE}]\,p}{c^\prime}}&\ \ \ \ \ \ \ \ \ \ \ \ Write_{SM}\\
  \trule{\trans{\inbr{\sigma,\,(\sigma\ x)s,\,\omega}}{p}{c^\prime}}{\trans{\inbr{\sigma,\,s,\,\omega}}{[\mathbf{LD \ x}]p}{c^\prime}}&\ \ \ \ \ \ \ \ \ \ \ \ LD_{SM}\\
  \trule{\trans{\inbr{\sigma\,[x\,\gets z],\,s,\,\omega}}{p}{c^\prime}}{\trans{\inbr{\sigma,\,zs,\,\omega}}{[\mathbf{ST \ x}]p}{c^\prime}}&\ \ \ \ \ \ \ \ \ \ \ \ ST_{SM}
  \end{array}
\)</span></p>
<p style="text-align: center" id="sm-bigstep"><em>Big-step operational semantics for stack machine</em></p>

  We describe this behavior, again, using a big-step operational semantics. First, we define the extended configuration <span class="math-tex">\(\mathscr{C}_{SM}\)</span>
  for stack machine as

<p style="text-align:center">
<span class="math-tex">\(
  \mathscr{C}_{SM}=St\times\mathbb{Z}^*\times\mathscr{W}
\)</span></p>

  <p>Each component of extended configuration — state, stack of integers, word — is familiar to us. Next we need
  to specify the big-step transition relation "<span class="math-tex">\(
\def\padding{\phantom{X}}
\def\transarrow{\xrightarrow}
\newcommand{\setpadding}[1]{\def\padding{#1}}
\def\subarrow{}
\newcommand{\setsubarrow}[1]{\def\subarrow{#1}}
\newcommand{\trans}[3]{{#1}\transarrow{\padding{\textstyle #2}\padding}\subarrow{#3}}
\newcommand{\transrel}{\setpadding{}\trans{}{}{}}
  \transrel\)</span>" for stack machines. The rules of the semantics
  are given in <a id="sm-bigstep">Big-step operational semantics for stack machine</a>. In the rules we additionaly surrounded the head instruction of a program
  by square brackets <code>[...]</code> to visually separate it from the rest of the program.</p>

  <p>The first rule, <span class="math-tex"  style="font-variant-caps: all-small-caps">\(Stop_{SM}\)</span>, is at the same time the single axiom in the semantics. It tells us that an empty
  program does not change the configuration. This, in particular, happens when all instructions of a program were
  already evaluated and there is nothing left to evaluate.</p>

  <p>All other rules follow the same pattern: they describe the effect of the first instruction of the current program,
  and then prescribe to evaluate the rest of the program using the same evluation relation.</p>

  <p>Rule <span class="math-tex"  style="font-variant-caps: all-small-caps">\(Binop_{SM}\)</span> describes the case when the first instruction is a binary operator. To succeed, this instruction
  requires atleast two integer values, <span class="math-tex">\(x\ and\ y\)</span>, to reside on the stack. If so, it combines these values using binary
  operator <span class="math-tex">\(\oplus\)</span> and puts the result back on the stack.
The correspondence between "<span class="math-tex">\(\otimes\)</span>"
and "<span class="math-tex">\(\oplus\)</span>" is,
  of course, the same as for the semantics of straight-line programs (see a table of the "Denotational Semantics" chapter).</p>

  <p>Rule <span class="math-tex"  style="font-variant-caps: all-small-caps">\(Const_{SM}\)</span>
corresponds to the case when the first instruction is <span class="math-tex">\(\mathbf{CONST\ z}\)</span>. This instruction
  puts its operand <span class="math-tex">\(z\)</span> on the stack.</p>

  <p>The next two symmetrical rules, <span class="math-tex" style="font-variant-caps: all-small-caps">\(Read_{SM}\)</span>}
and <span class="math-tex" style="font-variant-caps: all-small-caps">\(Write_{SM}\)</span>}, deal with instructions <span class="math-tex">\(\mathbf{READ}\)</span> and
<span class="math-tex">\(\mathbf{WRITE}\)</span> respectively. <span class="math-tex">\(\mathbf{READ}\)</span> reads a value from input stream and puts it on the stack; if the input stream is
  empty the instruction fails. <span class="math-tex">\(\mathbf{WRITE}\)</span> takes a valus from the top of the stack and puts it in the output stream; this
  instruction fails if the stack is empty.</p>

  <p>Finally, two last rules, <span class="math-tex"  style="font-variant-caps: all-small-caps">\(LD_{SM}\)</span>
and <span class="math-tex"  style="font-variant-caps: all-small-caps">\(ST_{SM}\)</span>, desribe the semantics of instructions <span class="math-tex">\(\mathbf{LD}\)</span> and
  <span class="math-tex">\(\mathbf{ST}\)</span>. Both instructions have an operand, the name of a variable. <span class="math-tex">\(\mathbf{LD\ x}\)</span>}
puts the value of variable <span class="math-tex">\(x\)</span>, associated
  in the current state <span class="math-tex">\(\sigma\)</span>, on the stack.
It fails if <span class="math-tex">\(\sigma\ x\)</span> is undefined.
<span class="math-tex">\(\mathbf{ST\ x}\)</span>} takes the top value from the
  stack and updates the current state <span class="math-tex">\(\sigma\)</span>
to associate <span class="math-tex">\(x\)</span> with this value. It fails if the stack is empty.</p>

  With the transition relation <span class="math-tex">\(
  \def\padding{\phantom{X}}
\def\transarrow{\xrightarrow}
\newcommand{\setpadding}[1]{\def\padding{#1}}
\def\subarrow{}
\newcommand{\setsubarrow}[1]{\def\subarrow{#1}}
\newcommand{\trans}[3]{{#1}\transarrow{\padding{\textstyle #2}\padding}\subarrow{#3}}
\newcommand{\transrel}{\setpadding{}\trans{}{}{}}

  \transrel\)</span> defined we can specify the "surface" semantics
for stack machine programs <span class="math-tex">\(
  \newcommand{\sembr}[1]{\llbracket{#1}\rrbracket}
\newcommand{\ph}{{\phantom{x}}}

  \sembr{\bullet}^\ph_{SM}\)</span>:

<p style="text-align:center">
<span class="math-tex">\(
  \def\padding{\phantom{X}}
\def\transarrow{\xrightarrow}
\newcommand{\setpadding}[1]{\def\padding{#1}}
\def\subarrow{}
\newcommand{\setsubarrow}[1]{\def\subarrow{#1}}
\newcommand{\trans}[3]{{#1}\transarrow{\padding{\textstyle #2}\padding}\subarrow{#3}}
\newcommand{\sembr}[1]{\llbracket{#1}\rrbracket}
\newcommand{\inbr}[1]{\left<{#1}\right>}
\newcommand{\ph}{{\phantom{x}}}
\newcommand{\trule}[2]{\frac{#1}{#2}}

  \begin{array}{c}
  \sembr{\bullet}^\ph_{SM} : \mathscr{S}\to \mathbb{Z}^*\to \mathbb{Z}^*\\[2mm]
  \trule{\trans{\inbr{\Lambda,\,\epsilon,\,\inbr{i,\,\epsilon}}}{p}{\inbr{\sigma,\,s,\,\omega}}}
  {\sembr{p}^\ph_{SM}\ i=\mathbf{out}{\ \omega}}
  \end{array}
\)</span></p>

  In other words, we take an input <span class="math-tex">\(i\)</span>,
create an initial configuration, consisting of an empty state <span class="math-tex">\(\Lambda\)</span>,
empty stack <span class="math-tex">\(\epsilon\)</span> and an
  initial world <span class="math-tex">\(
\newcommand{\inbr}[1]{\left<{#1}\right>}
  \inbr{i,\,\epsilon}\)</span>,
then run the program and, if it eventually comes to an end
with some final configuration <span class="math-tex">\(
\newcommand{\inbr}[1]{\left<{#1}\right>}
  \inbr{\sigma,\,s,\,\omega}\)</span>, we take
  output stream from this configuration's world as the result of the evaluation.

  As always, we can identify the following important properties of the semantics:

  <ul>
  <li><em>Determinism:</em> for each program and each configuration there is at most one rule that can be applied; thus, if (for arbitrary <span class="math-tex">\(i\)</span>
and <span class="math-tex">\(p\)</span>)
  <span class="math-tex">\(
\newcommand{\sembr}[1]{\llbracket{#1}\rrbracket}
\newcommand{\ph}{{\phantom{x}}}

    \sembr{p}^\ph_{SM}\ i=o\)</span> and
<span class="math-tex">\(
\newcommand{\sembr}[1]{\llbracket{#1}\rrbracket}
\newcommand{\ph}{{\phantom{x}}}

  \sembr{p}^\ph_{SM}\ i=o^\prime\)</span>
    then <span class="math-tex">\(o=o^\prime\)</span>;</li>
  <li><em>Compositionality</em>: the premise of each rule deals with programs one instruction shorter, than the conclusion. This, again, means that
    the principle of structural induction can be applied for proving the properties of the semantics.</li>
  </ul>

  It is also worth discussing the "shape" of derivation which the rules of the semantics generate. As we can see, each rule (except for the axiom) has
  exactly one premise, and the final configuration of the primise is at the same time the final configuration of the conclusion. This means that
  the derivations in this semantics have the form of a "tower"; the top of the tower corresponds to the application of the single axiom, which
  transfers its initial configuration to final one unchanged, and after that this final configuration is propagated down the tower in the right-hand side
  configurations of all involved rules. The effects of individual instructions can be traced in the bottom-up manner in the left-hand side configurations of the
  rules comprising the tower. To illustrate this structure, consider the following stack machine program:

<p style="text-align:center">

  <code>

  READ
  READ
  BINOP +
  WRITE
  </code>
</p>

  <p>The derivation "tower" which corresponds to the evaluation of this program for the input <span class="math-tex">\(
\newcommand{\inbr}[1]{\left<{#1}\right>}
  \inbr{2,\,3}\)</span> is shown in <a id="derivation-tower">"Derivation tower" example</a>. As always,
  we omit program for space considerations; the solid arrows connect the "floors" of the tower while dashed ones show the configurations' data flow.</p>

<img alt="" height="854" name="image.png" src="https://ucarecdn.com/ca239394-d625-4c19-bd9b-0b0f2c068aa8/" width="644" />
<p style="text-align: center" id="derivation-tower"><em>"Derivation tower" example</em></p>


